# CS234 - LLM-Enhanced Reinforcement Learning for Recommendation Systems
Final Project for the Course CS234 - Stanford

## Abstract
Achieving personalization in recommendation systems remains a significant challenge. While Large Language Models (LLMs) exhibit strong generalization capabilities, they are trained on broad internet-scale data and tend to capture expected preferences rather than truly personalized ones. This limitation makes it difficult for LLMs to model user-specific behaviors accurately. To address this, we explore an alternative approach by leveraging AI agents that simulate real user personas to enhance reward modeling. This work compares a transformer-based reward model (baseline) trained on the MovieLens dataset with an agent-driven reward model that generates synthetic user profiles using the TinyTroupe framework and GPT-4o. Experimental results indicate that while the transformer model achieves higher accuracy in explicit rating prediction, AI agents demonstrate superior ranking performance, as measured by NDCG, suggesting their potential to better capture user preferences. However, challenges remain in refining agent interactions and improving prompt engineering to enhance personalization.
